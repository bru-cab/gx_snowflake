{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57383f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark.functions import udf, avg, col,lit,call_udf,countDistinct,sproc,udf\n",
    "from snowflake.snowpark.types import IntegerType, FloatType, StringType, BooleanType\n",
    "import pandas as pd\n",
    "from configs.config import snowflake_conn_prop_local as snowflake_conn_prop\n",
    "import sys\n",
    "import json\n",
    "import platform\n",
    "import os,requests\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from src.DataValidationContext import *\n",
    "from snowflake.snowpark import version\n",
    "\n",
    "session = Session.builder.configs(snowflake_conn_prop).create()\n",
    "\n",
    "print(session.sql('select current_warehouse(), current_database(), current_schema()').collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6627092",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_HOME_DIR = '.'\n",
    "LOCAL_TEMP_DIR = os.path.join(PROJECT_HOME_DIR, 'temp') \n",
    "LOCAL_LIB_DIR = os.path.join(LOCAL_TEMP_DIR, 'libs')\n",
    "LOCAL_TARFile_DIR = os.path.join(LOCAL_TEMP_DIR, 'tarfiles')\n",
    "LIB_URLS = [\n",
    "    #'https://files.pythonhosted.org/packages/9f/57/1539d783553f3d67cea1b55d7fe494373c5c0c9af689d4c0e0c2d3197739/great_expectations-0.15.17-py3-none-any.whl'\n",
    "    'https://files.pythonhosted.org/packages/8e/9d/cecb12289f7967b15facf550a0bbb9c1e910968c3a61b91fd8cdb80aeb3c/great_expectations-0.15.14.tar.gz'\n",
    "    \n",
    "]\n",
    "\n",
    "for lib_url in LIB_URLS:\n",
    "    # get the file name, from the url\n",
    "    splits = lib_url.split('/')\n",
    "    tot_splits = len(splits)\n",
    "    target_file = splits[-1]\n",
    "    \n",
    "    local_lib_fl = f'{LOCAL_TARFile_DIR}/{target_file}'\n",
    "    print(local_lib_fl)\n",
    "\n",
    "    # Create a local directory for TAR and extracting tar..\n",
    "    Path(LOCAL_TARFile_DIR).mkdir(parents=True, exist_ok=True)\n",
    "    print(f'Create local dir: {LOCAL_TARFile_DIR}')\n",
    "\n",
    "    Path(LOCAL_LIB_DIR).mkdir(parents=True, exist_ok=True)\n",
    "    print(f'Create local dir: {LOCAL_LIB_DIR}')\n",
    "\n",
    "    print(f'Downloading library from PyPI to {LOCAL_TARFile_DIR} ...')\n",
    "    with open(local_lib_fl, \"wb\") as f:\n",
    "        r = requests.get(lib_url)\n",
    "        f.write(r.content)\n",
    "\n",
    "        \n",
    "# Extract GE tar file\n",
    "\n",
    "import tarfile\n",
    "file = tarfile.open(local_lib_fl)\n",
    "print(f'Started Extracting GE tar file to {LOCAL_TARFile_DIR} ...')\n",
    "file.extractall(f'{LOCAL_LIB_DIR}/ge')\n",
    "file.close()\n",
    "print(f'Done extracting GE tar file to {LOCAL_TARFile_DIR} ...')                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5e34f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the path for the great_expectation folder after the tar file is extracted.\n",
    "import glob\n",
    "ge_import_path=''\n",
    "for result in glob.iglob('./temp/libs/ge/great_expectations*'):\n",
    "    ge_import_path=result+'/great_expectations'\n",
    "print(ge_import_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dc59d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.config import snowflake_conn_prop_local as snowflake_conn_prop\n",
    "from src.DataValidationContext import GEDataValidationContext\n",
    "from src.BatchRequest import getBatchRequest\n",
    "from src.Expectations import  createExpectationSuite, createExpectations\n",
    "from src.RunLoadExpectations import runExpectaionValidation,loadValidationToDB\n",
    "from src.parsing import process_and_store_validation_results\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "session.sql(\"create or replace stage phani_greatexpectation\").collect()\n",
    "session.clear_packages()\n",
    "session.add_packages('packaging','python-dotenv','pyparsing','pandas','pycryptodomex','boto3','tzlocal','tqdm','requests','ruamel.yaml','ipython','jsonpatch','mistune','jinja2','jsonschema','scipy','altair','Click','colorama','cryptography','snowflake-snowpark-python','sqlalchemy','chardet','asn1crypto')\n",
    "session.clear_imports()\n",
    "session.add_import(ge_import_path)\n",
    "session.add_import('src')\n",
    "session.add_import('configs')\n",
    "\n",
    "\n",
    "@sproc(session=session,name=\"GEValidationResults\", replace=True, \n",
    "       return_type=StringType(),\n",
    "       input_types=[StringType(),StringType(),StringType()],\n",
    "       is_permanent=True, stage_location='@phani_greatexpectation/ge_AllLibs')\n",
    "\n",
    "def generateGEValidationResults(session: Session, db_name: str, schema_name: str ,table_name: str) -> str:\n",
    "        \n",
    "    from pathlib import Path\n",
    "    import os ,sys ,json ,tarfile, dotenv\n",
    "    \n",
    "    expecationsuitename = \"expecationsuitename\"\n",
    "    checkpointname = \"checkpointname\"\n",
    "    \n",
    "    sftablename = f'{db_name}.VALIDATION.{schema_name}_{table_name}_VALIDATION_RAW'\n",
    "    destination_table  = f'{db_name}.VALIDATION.{schema_name}_{table_name}_VALIDATION_CLEAN'\n",
    "\n",
    "    #Creating GE context inside code\n",
    "    ge=GEDataValidationContext(table_name)\n",
    "    context=ge.getContext()\n",
    "    \n",
    "    # Creating the Pandas DataFrame from Snowpark DF\n",
    "    # query = f' SELECT * FROM {db_name}.{schema_name}.{table_name} LIMIT 5000000'\n",
    "    # pd_df = session.sql(query).to_pandas()   \n",
    "\n",
    "    # convert all the date type columns into the same \n",
    "\n",
    "    desc_query = f\"DESC TABLE {db_name}.{schema_name}.{table_name}\"\n",
    "    columns_info = session.sql(desc_query).collect()\n",
    "    column_types = {row['name']: row['type'] for row in columns_info}\n",
    "    \n",
    "    select_clause = []\n",
    "    for col, col_type in column_types.items():\n",
    "        if 'DATE' in col_type or 'TIMESTAMP' in col_type:\n",
    "            select_clause.append(f\"TO_CHAR({col}, 'YYYY-MM-DD') AS {col}\")\n",
    "        else:\n",
    "            select_clause.append(col)\n",
    "    query = f\"SELECT {', '.join(select_clause)} FROM {db_name}.{schema_name}.{table_name}\"\n",
    "\n",
    "   # Execute the query and convert the results to a pandas DataFrame\n",
    "    pd_df = session.sql(query).to_pandas()\n",
    "\n",
    "\n",
    "    # Getting the batch request used while creating and running validation on expectations\n",
    "    local_batch_request=getBatchRequest(context,table_name,pd_df)\n",
    "    \n",
    "    #Creating GE expectation Suite\n",
    "    createExpectationSuite(context,expecationsuitename)\n",
    "\n",
    "    #Creating GE expecations\n",
    "    createExpectations(session, context,expecationsuitename,local_batch_request,pd_df, db_name,schema_name,table_name)\n",
    "\n",
    "    #Running GE validation \n",
    "    res=runExpectaionValidation(context,checkpointname,local_batch_request,expecationsuitename,table_name)\n",
    "    \n",
    "    #Loading validation result to Snowflake table.\n",
    "    loadValidationToDB(session,res,sftablename)\n",
    "\n",
    "\n",
    "    #Store the parsed data in a clean table\n",
    "    process_and_store_validation_results(session, sftablename, destination_table)\n",
    "\n",
    "    return f'VALIDATION RESULTS STORED IN {table_name}_VALIDATION_RAW & CLEAN DATA IN {table_name}_VALIDATION_CLEAN'.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b015334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling SP\n",
    "session.sql(\"call GEValidationResults('DATALAKE','GUS','USERS')\").collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
